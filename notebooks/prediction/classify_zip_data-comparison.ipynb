{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handgeschriebene Ziffern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der beiliegenden Beschreibung der Daten habe ich entnommen, dass es sich um handgeschriebene Ziffern handelt. Die mit 16x16 Bildpunkten abgespeichert sind. Der Beschreibung kann ich weiter entnehmen:\n",
    "\n",
    "*\"The data are in two gzipped files, and each line consists of the digit\n",
    "id (0-9) followed by the 256 grayscale values.\"*\n",
    "\n",
    "Es handelt sich also um eine Textdatei in der in jeder Zeile der Wert der geschriebenen Ziffer sowie die 16x16 = 256 Bildpunkte stehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumber(data, digit):\n",
    "    # wähle alle Zeilen in denen die erste Spalte (Spalte mit den Ziffer) mit 'digit' übereinstimmt\n",
    "    data_number = pd.DataFrame(data[data[0] == digit]) \n",
    "    # schneide die erste Spalte weg und gebe den rest zurück\n",
    "    separated_data = data_number.iloc[:,1:]\n",
    "    return separated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberImage(data, digit, aggregation):\n",
    "    # ruft die Hilfsfunktion getNumber auf um alle Bilddaten Daten zu einer Ziffer zu holen\n",
    "    image_data = getNumber(data, digit)\n",
    "    # bilde aus allen Bildern zu der einen Ziffer ein aggrigiertes Bild\n",
    "    if(aggregation == 'median'):\n",
    "        df1 = pd.DataFrame(image_data.median())\n",
    "    else:\n",
    "        df1 = pd.DataFrame(image_data.mean())        \n",
    "    \n",
    "    # wandle das format von (1,256) -> (16,16) und gebe diesen transformierten DataFrame zurück\n",
    "    return df1.values.reshape(16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, targets_train, targets_predict):\n",
    "        self.results_train = pd.DataFrame(targets_train, columns=[\"targets\"])\n",
    "        self.results_predict = pd.DataFrame(targets_predict, columns=[\"targets\"])\n",
    "\n",
    "        self.input_data = {}\n",
    "        \n",
    "        self.names = []        \n",
    "        self.configs = []\n",
    "\n",
    "        \n",
    "    def get_names(self):\n",
    "        return self.names\n",
    "    \n",
    "    \n",
    "    def get_results(self):\n",
    "        return self.results_train, self.results_predict\n",
    "    \n",
    "    def get_config_map(self):\n",
    "        for conf in self.configs:\n",
    "            print (\"CONFIG:\", conf['name'], conf['input_data_name'], \"\\tNum features:\", self.input_data[conf['input_data_name']]['data'].shape[1])\n",
    "    \n",
    "    \n",
    "    def add_input_data(self, name, data, description=\"\"):\n",
    "        self.input_data[name] = {'description': description, 'data': data}\n",
    "    \n",
    "    \n",
    "    def add_config(self, algo, name, input_data_name):\n",
    "        # TODO: add check for dublicate names\n",
    "        if input_data_name not in self.input_data:\n",
    "            print (\"ERROR: feature_set_name not found\")\n",
    "            return \n",
    "        \n",
    "        self.names.append(name)\n",
    "        self.configs.append({ 'name': name, 'algo': algo, 'input_data_name': input_data_name, 'fit': -1})\n",
    "        \n",
    "\n",
    "    def _fit(self, conf):\n",
    "        # get features\n",
    "        input_data = self.input_data[conf['input_data_name']]['data']\n",
    "\n",
    "        # fit the features\n",
    "        print (\"Fitting \", conf['name'], \"... \")\n",
    "        \n",
    "        start = time.time() # startzeit\n",
    "        conf['fit'] = conf['algo'].fit(input_data, self.results_train['targets'])\n",
    "        end = time.time() # startzeit\n",
    "        \n",
    "        print (\"done in \", end - start , \"s.\")\n",
    "\n",
    "        \n",
    "    \n",
    "    def _predict(self, conf, data, train):\n",
    "        if data.shape[1] != self.input_data[conf['input_data_name']]['data'].shape[1]:\n",
    "            print (\"ERROR: Number of input features does not match (\", conf['name'], \")\")\n",
    "            return\n",
    "        \n",
    "        print (\"Predicting data with\", conf['name'], \"... \")\n",
    "        \n",
    "        start = time.time() # startzeit\n",
    "        if train:\n",
    "            self.results_train[conf['name']] = conf['algo'].predict(data)\n",
    "        else:\n",
    "            self.results_predict[conf['name']] = conf['algo'].predict(data)\n",
    "        end = time.time() # startzeit\n",
    "        \n",
    "        print (\"done in \", end - start , \"s.\" )\n",
    "\n",
    "        \n",
    "    def fit(self):\n",
    "        '''Only trains algorithms if no fit has been calculated before'''\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] == -1:\n",
    "                self._fit(conf)\n",
    "\n",
    "                \n",
    "    def fit_all(self, data):\n",
    "        '''Trains all algorithms with given data'''\n",
    "        for conf in self.configs:\n",
    "            self._fit(conf)\n",
    "\n",
    "            \n",
    "    def refit(self, data):\n",
    "        '''Retrains all algorithms with given data that have been trained before'''\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1:\n",
    "                self._fit(conf)\n",
    "\n",
    "                \n",
    "    def predict(self, name, data, train=False):\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1 and conf['name'] == name:\n",
    "                self._predict(conf, data, train)\n",
    "\n",
    "    def predict_all(self, data, train=False):\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1:\n",
    "                self._predict(conf, data, train)\n",
    "\n",
    "                \n",
    "    def get_count_df(self, name):\n",
    "        count_matrix = np.zeros((10,10)) \n",
    "        for digit in range(0,10):\n",
    "            cluster_counts = self.results_train[self.results_train['targets'] == digit].groupby(name).count()['targets']\n",
    "            for cluster in cluster_counts.keys():\n",
    "                count_matrix[digit][cluster] = cluster_counts[cluster]\n",
    "        \n",
    "        col_names = []\n",
    "        for i in range(0,10):\n",
    "            col_names.append(\"C_\" + str(i))\n",
    "    \n",
    "        return pd.DataFrame(count_matrix, columns=col_names)\n",
    "\n",
    "    def get_norm_df(self, name):\n",
    "        count_df = self.get_count_df(name)\n",
    "        return count_df.divide(count_df.sum(1), axis=0)\n",
    "    \n",
    "    \n",
    "    def get_all_error_rates(self):\n",
    "        error_rates = {}\n",
    "        for conf in self.configs:\n",
    "            if (conf['fit'] != -1) & (conf['name'] in self.results_train.columns):\n",
    "                error_rates[conf['name']] = self.get_error_rate(conf['name'])\n",
    "        return error_rates\n",
    "                \n",
    "    def get_error_rate(self, name):\n",
    "        '''Determine classification error by identifying best fitting column assignment'''\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit header=None, wird die erste Zeile der Datei nicht als Header interpretiert \n",
    "#              (Man könnte den Header in einem solchen Fall als Zeile mit den Spaltenüberschriften bezeichnen)\n",
    "# mit sep=\" \", geben wir an, dass wir das Leerzeichen als Seperator verwenden wollen. \n",
    "#              D.h. zwei durch ein Leerzeichen separierte Werte sollen als zwei Werte eingelesen werden.\n",
    "data_train = pd.read_csv(\"../data/zip.train\", header=None, sep=\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data = data_train.dropna(axis=1, thresh=2) # lass alle Spalten mit mehr als 2 NaN (Not a Number) vom datensatz fallen \n",
    "cleaned_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Beschreibung der Daten wissen wir, dass es sich um die Ziffern und die dazugehörigen Bilder der Größe 16x16 Pixel handelt. Also in jeder Zeile steht in der 0-ten Spalte die Ziffer und in den folgenden 256 Spalten die einzelnen Pixel der Bilder. Also visualisieren wir diese nun einmal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "for i in range(0,10):\n",
    "    image = getNumberImage(cleaned_train_data,i,'mean')\n",
    "\n",
    "    # Call signature: subplot(nrows, ncols, index, **kwargs)\n",
    "    plt.subplot(2,5, 1 + i)\n",
    "    plt.imshow(image, cmap='hot', interpolation='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"../data/zip.test\", header=None, sep=\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_data = data_test.dropna(axis=1, thresh=2) # lass alle Spalten mit mehr als 2 NaN (Not a Number) vom datensatz fallen \n",
    "cleaned_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "for i in range(0,10):\n",
    "    image = getNumberImage(cleaned_test_data,i,'mean')\n",
    "\n",
    "    # Call signature: subplot(nrows, ncols, index, **kwargs)\n",
    "    plt.subplot(2,5, 1 + i)\n",
    "    plt.imshow(image, cmap='hot', interpolation='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in train und test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "input_data = cleaned_train_data.iloc[:,1:].values\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data = cleaned_test_data.iloc[:,1:].values\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set targets\n",
    "exp = Experiment(cleaned_train_data[0].values, cleaned_test_data[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input featurs are the individual pixels of the image - without transformation\n",
    "exp.add_input_data('256_pixel', input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification mit KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen an, dass jeder Bildpunkt ein Wert in dem 256 dimensionalen Raum der reelen Zahlen ist. In diesem Raum haben wir wie im 1-, 2-, oder 3-Dimensionalen auch das euklidische Abstandsmaß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.add_config(KNeighborsClassifier(n_neighbors=1), 'KNN_1', '256_pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.add_config(LogisticRegression(n_jobs=1), 'LogReg_1', '256_pixel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp.get_names())\n",
    "print(exp.get_config_map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersage und Fehler der Verfahren auf dem Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.predict_all(input_data, train=True)\n",
    "exp.predict_all(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train, results_test = exp.get_results()\n",
    "results_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3381d24efd66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNR:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KNN_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LogReg:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogReg_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"KNR:\",1.0*(results_test['targets'] == results_test['KNN_1']).sum()/results_test['targets'].count())\n",
    "print(\"LogReg:\",1.0*(results_test['targets'] == results_test['LogReg_1']).sum()/results_test['targets'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
